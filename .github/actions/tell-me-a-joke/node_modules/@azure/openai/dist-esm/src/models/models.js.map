{"version":3,"file":"models.js","sourceRoot":"","sources":["../../../src/models/models.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!\n *\n * Any changes you make here may be lost.\n *\n * If you need to make changes, please do so in the original source file, \\{project-root\\}/sources/custom\n */\n\nimport { ErrorModel } from \"@azure-rest/core-client\";\nimport { ContentFilterResults } from \"../api/models.js\";\n\n/**\n * Representation of the response data from an embeddings request.\n * Embeddings measure the relatedness of text strings and are commonly used for search, clustering,\n * recommendations, and other similar scenarios.\n */\nexport interface Embeddings {\n  /** Embedding values for the prompts submitted in the request. */\n  data: EmbeddingItem[];\n  /** Usage counts for tokens input using the embeddings API. */\n  usage: EmbeddingsUsage;\n}\n\n/** Representation of a single embeddings relatedness comparison. */\nexport interface EmbeddingItem {\n  /**\n   * List of embeddings value for the input prompt. These represent a measurement of the\n   * vector-based relatedness of the provided input.\n   */\n  embedding: number[];\n  /** Index of the prompt to which the EmbeddingItem corresponds. */\n  index: number;\n}\n\n/** Measurement of the amount of tokens used in this request and response. */\nexport interface EmbeddingsUsage {\n  /** Number of tokens sent in the original request. */\n  promptTokens: number;\n  /** Total number of tokens transacted in this request/response. */\n  totalTokens: number;\n}\n\n/**\n * Representation of the response data from a completions request.\n * Completions support a wide variety of tasks and generate text that continues from or \"completes\"\n * provided prompt data.\n */\nexport interface Completions {\n  /** A unique identifier associated with this completions response. */\n  id: string;\n  /**\n   * The first timestamp associated with generation activity for this completions response,\n   * represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.\n   */\n  created: Date;\n  /**\n   * Content filtering results for zero or more prompts in the request. In a streaming request,\n   * results for different prompts may arrive at different times or in different orders.\n   */\n  promptFilterResults?: PromptFilterResult[];\n  /**\n   * The collection of completions choices associated with this completions response.\n   * Generally, `n` choices are generated per provided prompt with a default value of 1.\n   * Token limits and other settings may limit the number of choices generated.\n   */\n  choices: Choice[];\n  /** Usage information for tokens processed and generated as part of this completions operation. */\n  usage: CompletionsUsage;\n}\n\n/** Content filtering results for a single prompt in the request. */\nexport interface PromptFilterResult {\n  /** The index of this prompt in the set of prompt results */\n  promptIndex: number;\n  /** Content filtering results for this prompt */\n  contentFilterResults?: ContentFilterResults;\n}\n\n/** Information about filtered content severity level and if it has been filtered or not. */\nexport interface ContentFilterResult {\n  /** Ratings for the intensity and risk level of filtered content. */\n  severity: ContentFilterSeverity;\n  /** A value indicating whether or not the content has been filtered. */\n  filtered: boolean;\n}\n\n/**\n * The representation of a single prompt completion as part of an overall completions request.\n * Generally, `n` choices are generated per provided prompt with a default value of 1.\n * Token limits and other settings may limit the number of choices generated.\n */\nexport interface Choice {\n  /** The generated text for a given completions prompt. */\n  text: string;\n  /** The ordered index associated with this completions choice. */\n  index: number;\n  /**\n   * Information about the content filtering category (hate, sexual, violence, self_harm), if it\n   * has been detected, as well as the severity level (very_low, low, medium, high-scale that\n   * determines the intensity and risk level of harmful content) and if it has been filtered or not.\n   */\n  contentFilterResults?: ContentFilterResults;\n  /** The log probabilities model for tokens associated with this completions choice. */\n  logprobs: CompletionsLogProbabilityModel | null;\n  /** Reason for finishing */\n  finishReason: CompletionsFinishReason | null;\n}\n\n/** Representation of a log probabilities model for a completions generation. */\nexport interface CompletionsLogProbabilityModel {\n  /** The textual forms of tokens evaluated in this probability model. */\n  tokens: string[];\n  /** A collection of log probability values for the tokens in this completions data. */\n  tokenLogprobs: (number | null)[];\n  /** A mapping of tokens to maximum log probability values in this completions data. */\n  topLogprobs: Record<string, number | null>[];\n  /** The text offsets associated with tokens in this completions data. */\n  textOffset: number[];\n}\n\n/** Representation of a log probabilities model for a completions generation. */\nexport interface CompletionsLogProbabilityModel {\n  /** The textual forms of tokens evaluated in this probability model. */\n  tokens: string[];\n  /** A collection of log probability values for the tokens in this completions data. */\n  tokenLogprobs: (number | null)[];\n  /** A mapping of tokens to maximum log probability values in this completions data. */\n  topLogprobs: Record<string, number | null>[];\n  /** The text offsets associated with tokens in this completions data. */\n  textOffset: number[];\n}\n\n/**\n * Representation of the token counts processed for a completions request.\n * Counts consider all tokens across prompts, choices, choice alternates, best_of generations, and\n * other consumers.\n */\nexport interface CompletionsUsage {\n  /** The number of tokens generated across all completions emissions. */\n  completionTokens: number;\n  /** The number of tokens in the provided prompts for the completions request. */\n  promptTokens: number;\n  /** The total number of tokens processed for the completions request and response. */\n  totalTokens: number;\n}\n\n/** A single, role-attributed message within a chat completion interaction. */\nexport interface ChatMessage {\n  /** The role associated with this message payload. */\n  role: ChatRole;\n  /** The text associated with this message payload. */\n  content: string | null;\n  /**\n   * The name of the author of this message. `name` is required if role is `function`, and it should be the name of the\n   * function whose response is in the `content`. May contain a-z, A-Z, 0-9, and underscores, with a maximum length of\n   * 64 characters.\n   */\n  name?: string;\n  /** The name and arguments of a function that should be called, as generated by the model. */\n  functionCall?: FunctionCall;\n  /**\n   *   Additional context data associated with a chat message when requesting chat completions using compatible Azure\n   *   OpenAI chat extensions. This includes information like the intermediate data source retrievals used to service a\n   *   request.\n   *   This context information is only populated when using Azure OpenAI with chat extensions capabilities configured.\n   */\n  context?: AzureChatExtensionsMessageContext;\n}\n\n/** The name and arguments of a function that should be called, as generated by the model. */\nexport interface FunctionCall {\n  /** The name of the function to call. */\n  name: string;\n  /**\n   * The arguments to call the function with, as generated by the model in JSON format.\n   * Note that the model does not always generate valid JSON, and may hallucinate parameters\n   * not defined by your function schema. Validate the arguments in your code before calling\n   * your function.\n   */\n  arguments: string;\n}\n\n/**\n *   A representation of the additional context information available when Azure OpenAI chat extensions are involved\n *   in the generation of a corresponding chat completions response. This context information is only populated when\n *   using an Azure OpenAI request configured to use a matching extension.\n */\nexport interface AzureChatExtensionsMessageContext {\n  /**\n   *   The contextual message payload associated with the Azure chat extensions used for a chat completions request.\n   *   These messages describe the data source retrievals, plugin invocations, and other intermediate steps taken in the\n   *   course of generating a chat completions response that was augmented by capabilities from Azure OpenAI chat\n   *   extensions.\n   */\n  messages?: ChatMessage[];\n}\n\n/** The definition of a caller-specified function that chat completions may invoke in response to matching user input. */\nexport interface FunctionDefinition {\n  /** The name of the function to be called. */\n  name: string;\n  /**\n   * A description of what the function does. The model will use this description when selecting the function and\n   * interpreting its parameters.\n   */\n  description?: string;\n  /** The parameters the functions accepts, described as a JSON Schema object. */\n  parameters?: Record<string, any>;\n}\n\n/**\n * A structure that specifies the exact name of a specific, request-provided function to use when processing a chat\n * completions operation.\n */\nexport interface FunctionName {\n  /** The name of the function to call. */\n  name: string;\n}\n\n/**\n *   A representation of configuration data for a single Azure OpenAI chat extension. This will be used by a chat\n *   completions request that should use Azure OpenAI chat extensions to augment the response behavior.\n *   The use of this configuration is compatible only with Azure OpenAI.\n */\nexport interface AzureChatExtensionConfiguration {\n  /**\n   *   The label for the type of an Azure chat extension. This typically corresponds to a matching Azure resource.\n   *   Azure chat extensions are only compatible with Azure OpenAI.\n   */\n  type: AzureChatExtensionType;\n  /**\n   *   The configuration payload used for the Azure chat extension. The structure payload details are specific to the\n   *   extension being configured.\n   *   Azure chat extensions are only compatible with Azure OpenAI.\n   */\n  parameters: Record<string, any>;\n}\n\n/**\n * Representation of the response data from a chat completions request.\n * Completions support a wide variety of tasks and generate text that continues from or \"completes\"\n * provided prompt data.\n */\nexport interface ChatCompletions {\n  /** A unique identifier associated with this chat completions response. */\n  id: string;\n  /**\n   * The first timestamp associated with generation activity for this completions response,\n   * represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.\n   */\n  created: Date;\n  /**\n   * The collection of completions choices associated with this completions response.\n   * Generally, `n` choices are generated per provided prompt with a default value of 1.\n   * Token limits and other settings may limit the number of choices generated.\n   */\n  choices: ChatChoice[];\n  /**\n   * Content filtering results for zero or more prompts in the request. In a streaming request,\n   * results for different prompts may arrive at different times or in different orders.\n   */\n  promptFilterResults?: PromptFilterResult[];\n  /** Usage information for tokens processed and generated as part of this completions operation. */\n  usage?: CompletionsUsage;\n}\n\n/**\n * The representation of a single prompt completion as part of an overall chat completions request.\n * Generally, `n` choices are generated per provided prompt with a default value of 1.\n * Token limits and other settings may limit the number of choices generated.\n */\nexport interface ChatChoice {\n  /** The chat message for a given chat completions prompt. */\n  message?: ChatMessage;\n  /** The ordered index associated with this chat completions choice. */\n  index: number;\n  /** The reason that this chat completions choice completed its generated. */\n  finishReason: CompletionsFinishReason | null;\n  /** The delta message content for a streaming response. */\n  delta?: ChatMessage;\n  /**\n   * Information about the content filtering category (hate, sexual, violence, self_harm), if it\n   * has been detected, as well as the severity level (very_low, low, medium, high-scale that\n   * determines the intensity and risk level of harmful content) and if it has been filtered or not.\n   */\n  contentFilterResults?: ContentFilterResults;\n}\n\n/** A polling status update or final response payload for an image operation. */\nexport interface BatchImageGenerationOperationResponse {\n  /** The ID of the operation. */\n  id: string;\n  /** A timestamp when this job or item was created (in unix epochs). */\n  created: Date;\n  /** A timestamp when this operation and its associated images expire and will be deleted (in unix epochs). */\n  expires?: number;\n  /** The result of the operation if the operation succeeded. */\n  result?: ImageGenerations;\n  /** The status of the operation */\n  status: AzureOpenAIOperationState;\n  /** The error if the operation failed. */\n  error?: ErrorModel;\n}\n\n/** The result of the operation if the operation succeeded. */\nexport interface ImageGenerations {\n  /** A timestamp when this job or item was created (in unix epochs). */\n  created: Date;\n  /** The images generated by the operator. */\n  data: ImageLocation[] | ImagePayload[];\n}\n\n/** An image response item that provides a URL from which an image may be accessed. */\nexport interface ImageLocation {\n  /** The URL that provides temporary access to download the generated image. */\n  url: string;\n}\n\n/** An image response item that directly represents the image data as a base64-encoded string. */\nexport interface ImagePayload {\n  /** The complete data for an image represented as a base64-encoded string. */\n  base64Data: string;\n}\n\n/** Ratings for the intensity and risk level of harmful content. */\n/** \"safe\", \"low\", \"medium\", \"high\" */\nexport type ContentFilterSeverity = string;\n/** Representation of the manner in which a completions response concluded. */\n/** \"stop\", \"length\", \"content_filter\", \"function_call\" */\nexport type CompletionsFinishReason = string;\n/** A description of the intended purpose of a message within a chat completions interaction. */\n/** \"system\", \"assistant\", \"user\", \"function\", \"tool\" */\nexport type ChatRole = string;\n/**\n * The collection of predefined behaviors for handling request-provided function information in a chat completions\n * operation.\n */\n/** \"auto\", \"none\" */\nexport type FunctionCallPreset = string;\n/**\n *   A representation of configuration data for a single Azure OpenAI chat extension. This will be used by a chat\n *   completions request that should use Azure OpenAI chat extensions to augment the response behavior.\n *   The use of this configuration is compatible only with Azure OpenAI.\n */\n/** \"AzureCognitiveSearch\" */\nexport type AzureChatExtensionType = string;\n/** The state of a job or item. */\n/** \"notRunning\", \"running\", \"succeeded\", \"canceled\", \"failed\" */\nexport type AzureOpenAIOperationState = string;\n/** The desired size of the generated images. Must be one of 256x256, 512x512, or 1024x1024. */\n/** \"256x256\", \"512x512\", \"1024x1024\" */\nexport type ImageSize = string;\n/** The format in which the generated images are returned. */\n/** \"url\", \"b64_json\" */\nexport type ImageGenerationResponseFormat = string;\n"]}