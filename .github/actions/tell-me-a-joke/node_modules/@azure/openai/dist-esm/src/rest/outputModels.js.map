{"version":3,"file":"outputModels.js","sourceRoot":"","sources":["../../../src/rest/outputModels.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!\n *\n * Any changes you make here may be lost.\n *\n * If you need to make changes, please do so in the original source file, \\{project-root\\}/sources/custom\n */\n\nimport { ErrorModel } from \"@azure-rest/core-client\";\n\n/** A specific deployment */\nexport interface DeploymentOutput {\n  /** Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request. */\n  readonly deploymentId: string;\n}\n\n/**\n * Representation of the response data from an embeddings request.\n * Embeddings measure the relatedness of text strings and are commonly used for search, clustering,\n * recommendations, and other similar scenarios.\n */\nexport interface EmbeddingsOutput {\n  /** Embedding values for the prompts submitted in the request. */\n  data: Array<EmbeddingItemOutput>;\n  /** Usage counts for tokens input using the embeddings API. */\n  usage: EmbeddingsUsageOutput;\n}\n\n/** Representation of a single embeddings relatedness comparison. */\nexport interface EmbeddingItemOutput {\n  /**\n   * List of embeddings value for the input prompt. These represent a measurement of the\n   * vector-based relatedness of the provided input.\n   */\n  embedding: number[];\n  /** Index of the prompt to which the EmbeddingItem corresponds. */\n  index: number;\n}\n\n/** Measurement of the amount of tokens used in this request and response. */\nexport interface EmbeddingsUsageOutput {\n  /** Number of tokens sent in the original request. */\n  prompt_tokens: number;\n  /** Total number of tokens transacted in this request/response. */\n  total_tokens: number;\n}\n\n/**\n * Representation of the response data from a completions request.\n * Completions support a wide variety of tasks and generate text that continues from or \"completes\"\n * provided prompt data.\n */\nexport interface CompletionsOutput {\n  /** A unique identifier associated with this completions response. */\n  id: string;\n  /**\n   * The first timestamp associated with generation activity for this completions response,\n   * represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.\n   */\n  created: number;\n  /**\n   * Content filtering results for zero or more prompts in the request. In a streaming request,\n   * results for different prompts may arrive at different times or in different orders.\n   */\n  prompt_annotations?: Array<PromptFilterResultOutput>;\n  /**\n   * The collection of completions choices associated with this completions response.\n   * Generally, `n` choices are generated per provided prompt with a default value of 1.\n   * Token limits and other settings may limit the number of choices generated.\n   */\n  choices: Array<ChoiceOutput>;\n  /** Usage information for tokens processed and generated as part of this completions operation. */\n  usage: CompletionsUsageOutput;\n}\n\n/** Content filtering results for a single prompt in the request. */\nexport interface PromptFilterResultOutput {\n  /** The index of this prompt in the set of prompt results */\n  prompt_index: number;\n  /** Content filtering results for this prompt */\n  content_filter_results?: ContentFilterResultsOutput;\n}\n\n/** Information about the content filtering category, if it has been detected. */\nexport interface ContentFilterResultsOutput {\n  /**\n   * Describes language related to anatomical organs and genitals, romantic relationships,\n   *  acts portrayed in erotic or affectionate terms, physical sexual acts, including\n   *  those portrayed as an assault or a forced sexual violent act against one’s will,\n   *  prostitution, pornography, and abuse.\n   */\n  sexual?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to hurt, injure, damage, or\n   * kill someone or something; describes weapons, etc.\n   */\n  violence?: ContentFilterResultOutput;\n  /**\n   * Describes language attacks or uses that include pejorative or discriminatory language\n   * with reference to a person or identity group on the basis of certain differentiating\n   * attributes of these groups including but not limited to race, ethnicity, nationality,\n   * gender identity and expression, sexual orientation, religion, immigration status, ability\n   * status, personal appearance, and body size.\n   */\n  hate?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to purposely hurt, injure,\n   * or damage one’s body, or kill oneself.\n   */\n  self_harm?: ContentFilterResultOutput;\n  /**\n   * Describes an error returned if the content filtering system is\n   * down or otherwise unable to complete the operation in time.\n   */\n  error?: ErrorModel;\n}\n\n/** Information about filtered content severity level and if it has been filtered or not. */\nexport interface ContentFilterResultOutput {\n  /**\n   * Ratings for the intensity and risk level of filtered content.\n   *\n   * Possible values: safe, low, medium, high\n   */\n  severity: string;\n  /** A value indicating whether or not the content has been filtered. */\n  filtered: boolean;\n}\n\n/**\n * The representation of a single prompt completion as part of an overall completions request.\n * Generally, `n` choices are generated per provided prompt with a default value of 1.\n * Token limits and other settings may limit the number of choices generated.\n */\nexport interface ChoiceOutput {\n  /** The generated text for a given completions prompt. */\n  text: string;\n  /** The ordered index associated with this completions choice. */\n  index: number;\n  /**\n   * Information about the content filtering category (hate, sexual, violence, self_harm), if it\n   * has been detected, as well as the severity level (very_low, low, medium, high-scale that\n   * determines the intensity and risk level of harmful content) and if it has been filtered or not.\n   */\n  content_filter_results?: ContentFilterResultsOutput;\n  /** The log probabilities model for tokens associated with this completions choice. */\n  logprobs: CompletionsLogProbabilityModelOutput | null;\n  /** Reason for finishing */\n  finish_reason: string | null;\n}\n\n/** Representation of a log probabilities model for a completions generation. */\nexport interface CompletionsLogProbabilityModelOutput {\n  /** The textual forms of tokens evaluated in this probability model. */\n  tokens: string[];\n  /** A collection of log probability values for the tokens in this completions data. */\n  token_logprobs: (number | null)[];\n  /** A mapping of tokens to maximum log probability values in this completions data. */\n  top_logprobs: Record<string, number | null>[];\n  /** The text offsets associated with tokens in this completions data. */\n  text_offset: number[];\n}\n\n/**\n * Representation of the token counts processed for a completions request.\n * Counts consider all tokens across prompts, choices, choice alternates, best_of generations, and\n * other consumers.\n */\nexport interface CompletionsUsageOutput {\n  /** The number of tokens generated across all completions emissions. */\n  completion_tokens: number;\n  /** The number of tokens in the provided prompts for the completions request. */\n  prompt_tokens: number;\n  /** The total number of tokens processed for the completions request and response. */\n  total_tokens: number;\n}\n\n/** A single, role-attributed message within a chat completion interaction. */\nexport interface ChatMessageOutput {\n  /**\n   * The role associated with this message payload.\n   *\n   * Possible values: system, assistant, user, function, tool\n   */\n  role: string;\n  /** The text associated with this message payload. */\n  content: string | null;\n  /**\n   * The name of the author of this message. `name` is required if role is `function`, and it should be the name of the\n   * function whose response is in the `content`. May contain a-z, A-Z, 0-9, and underscores, with a maximum length of\n   * 64 characters.\n   */\n  name?: string;\n  /** The name and arguments of a function that should be called, as generated by the model. */\n  function_call?: FunctionCallOutput;\n  /**\n   *   Additional context data associated with a chat message when requesting chat completions using compatible Azure\n   *   OpenAI chat extensions. This includes information like the intermediate data source retrievals used to service a\n   *   request.\n   *   This context information is only populated when using Azure OpenAI with chat extensions capabilities configured.\n   */\n  context?: AzureChatExtensionsMessageContextOutput;\n}\n\n/** The name and arguments of a function that should be called, as generated by the model. */\nexport interface FunctionCallOutput {\n  /** The name of the function to call. */\n  name: string;\n  /**\n   * The arguments to call the function with, as generated by the model in JSON format.\n   * Note that the model does not always generate valid JSON, and may hallucinate parameters\n   * not defined by your function schema. Validate the arguments in your code before calling\n   * your function.\n   */\n  arguments: string;\n}\n\n/**\n *   A representation of the additional context information available when Azure OpenAI chat extensions are involved\n *   in the generation of a corresponding chat completions response. This context information is only populated when\n *   using an Azure OpenAI request configured to use a matching extension.\n */\nexport interface AzureChatExtensionsMessageContextOutput {\n  /**\n   *   The contextual message payload associated with the Azure chat extensions used for a chat completions request.\n   *   These messages describe the data source retrievals, plugin invocations, and other intermediate steps taken in the\n   *   course of generating a chat completions response that was augmented by capabilities from Azure OpenAI chat\n   *   extensions.\n   */\n  messages?: Array<ChatMessageOutput>;\n}\n\n/**\n * Representation of the response data from a chat completions request.\n * Completions support a wide variety of tasks and generate text that continues from or \"completes\"\n * provided prompt data.\n */\nexport interface ChatCompletionsOutput {\n  /** A unique identifier associated with this chat completions response. */\n  id: string;\n  /**\n   * The first timestamp associated with generation activity for this completions response,\n   * represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.\n   */\n  created: number;\n  /**\n   * The collection of completions choices associated with this completions response.\n   * Generally, `n` choices are generated per provided prompt with a default value of 1.\n   * Token limits and other settings may limit the number of choices generated.\n   */\n  choices: Array<ChatChoiceOutput>;\n  /**\n   * Content filtering results for zero or more prompts in the request. In a streaming request,\n   * results for different prompts may arrive at different times or in different orders.\n   */\n  prompt_annotations?: Array<PromptFilterResultOutput>;\n  /** Usage information for tokens processed and generated as part of this completions operation. */\n  usage: CompletionsUsageOutput;\n}\n\n/**\n * The representation of a single prompt completion as part of an overall chat completions request.\n * Generally, `n` choices are generated per provided prompt with a default value of 1.\n * Token limits and other settings may limit the number of choices generated.\n */\nexport interface ChatChoiceOutput {\n  /** The chat message for a given chat completions prompt. */\n  message?: ChatMessageOutput;\n  /** The ordered index associated with this chat completions choice. */\n  index: number;\n  /** The reason that this chat completions choice completed its generated. */\n  finish_reason: string | null;\n  /** The delta message content for a streaming response. */\n  delta?: ChatMessageOutput;\n  /**\n   * Information about the content filtering category (hate, sexual, violence, self_harm), if it\n   * has been detected, as well as the severity level (very_low, low, medium, high-scale that\n   * determines the intensity and risk level of harmful content) and if it has been filtered or not.\n   */\n  content_filter_results?: ContentFilterResultsOutput;\n}\n\n/** A polling status update or final response payload for an image operation. */\nexport interface BatchImageGenerationOperationResponseOutput {\n  /** The ID of the operation. */\n  id: string;\n  /** A timestamp when this job or item was created (in unix epochs). */\n  created: number;\n  /** A timestamp when this operation and its associated images expire and will be deleted (in unix epochs). */\n  expires?: number;\n  /** The result of the operation if the operation succeeded. */\n  result?: ImageGenerationsOutput;\n  /**\n   * The status of the operation\n   *\n   * Possible values: notRunning, running, succeeded, canceled, failed\n   */\n  status: string;\n  /** The error if the operation failed. */\n  error?: ErrorModel;\n}\n\n/** The result of the operation if the operation succeeded. */\nexport interface ImageGenerationsOutput {\n  /** A timestamp when this job or item was created (in unix epochs). */\n  created: number;\n  /** The images generated by the operator. */\n  data: Array<ImageLocationOutput> | Array<ImagePayloadOutput>;\n}\n\n/** An image response item that provides a URL from which an image may be accessed. */\nexport interface ImageLocationOutput {\n  /** The URL that provides temporary access to download the generated image. */\n  url: string;\n}\n\n/** An image response item that directly represents the image data as a base64-encoded string. */\nexport interface ImagePayloadOutput {\n  /** The complete data for an image represented as a base64-encoded string. */\n  b64_json: string;\n}\n\n/** Represents the request data used to generate images. */\nexport interface ImageGenerationOptionsOutput {\n  /** A description of the desired images. */\n  prompt: string;\n  /** The number of images to generate (defaults to 1). */\n  n?: number;\n  /**\n   * The desired size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 (defaults to 1024x1024).\n   *\n   * Possible values: 256x256, 512x512, 1024x1024\n   */\n  size?: string;\n  /**\n   *   The format in which image generation response items should be presented.\n   *   Azure OpenAI only supports URL response items.\n   *\n   * Possible values: url, b64_json\n   */\n  response_format?: string;\n  /** A unique identifier representing your end-user, which can help to monitor and detect abuse. */\n  user?: string;\n}\n"]}